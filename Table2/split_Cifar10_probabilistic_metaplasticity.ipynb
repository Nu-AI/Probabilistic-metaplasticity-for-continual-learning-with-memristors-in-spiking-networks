{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7579cd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.matlib\n",
    "import multiprocessing\n",
    "from tqdm import notebook\n",
    "import json\n",
    "import copy\n",
    "from tqdm import trange, tqdm\n",
    "from multiprocessing import Pool, RLock\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ec7a6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_param_config(mean_res, std_res, n_cross, w_hid_max, w_out_max):\n",
    "\t# creating the array with n_cross res states\n",
    "\tstates = []\n",
    "\tfor i in range(len(mean_res)-1):\n",
    "\t\ttemp = np.ones(n_cross)*mean_res[i]\n",
    "\t\tfor j in range(n_cross):\n",
    "\t\t\ttemp1 = copy.deepcopy(temp)\n",
    "\t\t\tstates.append(temp1)\n",
    "\t\t\ttemp[n_cross-j-1] = mean_res[i+1]\n",
    "\tstates.append(np.ones(n_cross)*mean_res[len(mean_res)-1])\n",
    "\n",
    "\t# calculate the parallel equivalent resistance\n",
    "\tp = []\n",
    "\tfor state in states:\n",
    "\t\ttemp = 0\n",
    "\t\tfor j in range(len(state)):\n",
    "\t\t\ttemp = temp + 1/state[j]\n",
    "\t\tp.append(1/temp)\n",
    "\n",
    "\t# compute the feedback and bias resistance for given weight range\n",
    "\tb_h = np.array([[w_hid_max], [-w_hid_max]])\n",
    "\tb_o = np.array([[w_out_max], [-w_out_max]])\n",
    "\tA = np.array([[1/p[len(p)-1], -1], [1/p[0], -1]])\n",
    "\tx_h = np.matmul(np.linalg.inv(A), b_h)\n",
    "\tx_o = np.matmul(np.linalg.inv(A), b_o)\n",
    "\n",
    "\tR_fh = x_h[0][0]\n",
    "\tR_bh = R_fh/x_h[1][0]\n",
    "\tR_fo = x_o[0][0]\n",
    "\tR_bo = R_fo/x_o[1][0]\n",
    "\t\n",
    "\treturn R_fh, R_bh, R_fo, R_bo\n",
    "\t\n",
    "def res_to_weight(r, R_f, R_b):   \n",
    "\tmax_axis = len(r.shape)-1\n",
    "\tr_tot = 1/(np.sum(1/r, axis = max_axis))    \n",
    "\tweight = R_f/r_tot - R_f/R_b\n",
    "\treturn weight\n",
    "\n",
    "\n",
    "def weight_initialize_var(n1, n2, R_f, R_b, n_cross, w_max):\n",
    "\tstates = []\n",
    "\tstatesP = []\n",
    "\tfor i in range(len(mean_res)-1):\n",
    "\t\ttemp = np.ones(n_cross)*mean_res[i]\n",
    "\t\ttempP = np.ones(n_cross)*i\n",
    "\t\tfor j in range(n_cross):\n",
    "\t\t\ttemp1 = copy.deepcopy(temp)\n",
    "\t\t\ttemp1P = copy.deepcopy(tempP)\n",
    "\t\t\tstates.append(temp1)\n",
    "\t\t\tstatesP.append(temp1P)\n",
    "\t\t\ttemp[n_cross-j-1] = mean_res[i+1]\n",
    "\t\t\ttempP[n_cross-j-1] = i+1\n",
    "\tstates.append(np.ones(n_cross)*mean_res[len(mean_res)-1])\n",
    "\tstatesP.append(np.ones(n_cross)*(len(mean_res)-1))\n",
    "\tstates = np.array(states)\n",
    "\tstatesP = np.array(statesP)             \n",
    "\tw_list = res_to_weight(states, R_f, R_b)\n",
    "\tn_tot = n1*n2\n",
    "\tn_ind1 = np.where((w_list<=-0.5)&(w_list>=-1))\n",
    "\tn_ind2 = np.where((w_list<0)&(w_list>=-0.5))\n",
    "\tn_ind3 = np.where((w_list>=0)&(w_list<0.5))\n",
    "\tn_ind4 = np.where((w_list<=1)&(w_list>=0.5))\n",
    "\ts1 = numpy.random.choice( n_ind1[0] , size = int(n_tot/4), replace = True, p = None)\n",
    "\ts2 = numpy.random.choice( n_ind2[0] , size = int(n_tot/4), replace = True, p = None)\n",
    "\ts3 = numpy.random.choice( n_ind3[0] , size = int(n_tot/4), replace = True, p = None)\n",
    "\ts4 = numpy.random.choice( n_ind4[0] , size = int(n_tot/4), replace = True, p = None)\n",
    "\tind = numpy.concatenate ((s1, s2, s3, s4), axis = 0, out = None)\n",
    "\tind_rand = numpy.random.choice( ind , size = int(n_tot), replace = False, p = None)\n",
    "\tr = np.zeros((n_tot, n_cross))\n",
    "\trP = np.zeros((n_tot, n_cross))\n",
    "\trP = statesP[ind_rand]\n",
    "\tfor i in range(n_res_level):\n",
    "\t\tloc = np.where(rP==i)\n",
    "\t\tif len(loc[0])!=0:\n",
    "\t\t\tr[loc] = np.random.normal(mean_res[i], std_res[i], len(loc[0]))\n",
    "\tr = np.reshape(r, [n1, n2, n_cross])\n",
    "\trP = np.reshape(rP, [n1, n2, n_cross])\n",
    "\tw = res_to_weight(r, R_f, R_b)\n",
    "\treturn w, r\n",
    "\t\n",
    "\t\n",
    "def infer_level(r_up):\n",
    "\ttemp_res = np.matlib.repmat(np.reshape(r_up, (len(r_up),1)),1, n_res_level)\n",
    "\tdiff = abs(temp_res-mean_res)\n",
    "\tinferred_level = np.argmin(diff, axis =1)\n",
    "\treturn inferred_level\n",
    "\n",
    "def res_program(r, up_dir):\n",
    "\tr_P = infer_level(r)\n",
    "\tr_P = r_P + up_dir\n",
    "\tr_P[np.where(r_P > len(mean_res)-1)] = len(mean_res)-1\n",
    "\tr_P[np.where(r_P < 0)] = 0\n",
    "\tr = np.zeros_like(r_P)\n",
    "\tfor i in range(n_res_level):\n",
    "\t\tloc = np.where(r_P==i)\n",
    "\t\tr[loc] = np.random.normal(mean_res[i], std_res[i], len(loc[0]))\n",
    "\treturn r \n",
    "\t\n",
    "def make_spike_trains(freqs, n_steps):\n",
    "\t''' Create an array of Poisson spike trains\n",
    "\t\tParameters:\n",
    "\t\t\tfreqs: Array of mean spiking frequencies.\n",
    "\t\t\tn_steps: Number of time steps\n",
    "\t'''\n",
    "\tr = np.random.rand(len(freqs), n_steps)\n",
    "\tspike_trains = np.where(r <= np.reshape(freqs, (len(freqs),1)), 1, 0)\n",
    "\treturn spike_trains\n",
    "\n",
    "def MNIST_to_Spikes(maxF, im, t_sim, dt):\n",
    "\t''' Generate spike train array from MNIST image.\n",
    "\t\tParameters:\n",
    "\t\t\tmaxF: max frequency, corresponding to 1.0 pixel value\n",
    "\t\t\tFR: MNIST image (784,)\n",
    "\t\t\tt_sim: duration of sample presentation (seconds)\n",
    "\t\t\tdt: simulation time step (seconds)\n",
    "\t'''\n",
    "\tn_steps = int(t_sim / dt) #  sample presentation duration in sim steps\n",
    "\tfreqs = im * maxF * dt # scale [0,1] pixel values to [0,maxF] and flatten\n",
    "\tSpikeMat = make_spike_trains(freqs, n_steps)\n",
    "\treturn SpikeMat\n",
    "\t\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "\t\"\"\" Special json encoder for numpy types \"\"\"\n",
    "\tdef default(self, obj):\n",
    "\t\tif isinstance(obj, (np.int_, np.intc, np.intp, np.int8,\n",
    "\t\t\t\t\t\t\tnp.int16, np.int32, np.int64, np.uint8,\n",
    "\t\t\t\t\t\t\tnp.uint16, np.uint32, np.uint64)):\n",
    "\t\t\treturn int(obj)\n",
    "\t\telif isinstance(obj, (np.float_, np.float16, np.float32,\n",
    "\t\t\t\t\t\t\t  np.float64)):\n",
    "\t\t\treturn float(obj)\n",
    "\t\telif isinstance(obj, (np.ndarray,)):\n",
    "\t\t\treturn obj.tolist()\n",
    "\t\treturn json.JSONEncoder.default(self, obj)\n",
    "\t\t\n",
    "def check_accuracy(images, labels, w_in, w_out):\n",
    "\t\"\"\"Present a set of labeled images to the network and count correct inferences\n",
    "\t:param images: images\n",
    "\t:param labels: labels\n",
    "\t:return: fraction of labels correctly inferred\n",
    "\t\"\"\"\n",
    "\tnumCorrect = 0\n",
    "\n",
    "\tfor u in range(len(images)):\n",
    "\t\tcnt = np.zeros(n_out)\n",
    "\t\tspikeMat = MNIST_to_Spikes(MaxF, images[u], tSim, dt_conv)\n",
    "\n",
    "\t\t# Initialize hidden layer variables\n",
    "\t\tI1 = np.zeros(n_h1)\n",
    "\t\tV1 = np.zeros(n_h1)\n",
    "\n",
    "\t\t# Initialize output layer variables\n",
    "\t\tI2 = np.zeros(n_out)\n",
    "\t\tV2 = np.zeros(n_out)\n",
    "\n",
    "\t\t# Initialize firing time variables\n",
    "\t\tts1 = np.full(n_h1, -t_refr)\n",
    "\t\tts2 = np.full(n_out, -t_refr)\n",
    "\n",
    "\n",
    "\t\tfor t in range(nBins):\n",
    "\t\t\t# Update hidden neuron synaptic currents\n",
    "\t\t\tI1 += (dt/t_syn) * (w_in.dot(spikeMat[:, t]) - I1)\n",
    "\n",
    "\t\t\t# Update hidden neuron membrane potentials\n",
    "\t\t\tV1 += (dt/t_m) * ((V_rest - V1) + I1 * R)\n",
    "\t\t\tV1[V1 < -Vth/10] = -Vth/10 # Limit negative potential to -Vth/10\n",
    "\n",
    "\t\t\t# Clear membrane potential of hidden neurons that spiked more\n",
    "\t\t\t# recently than t_refr\n",
    "\t\t\tV1[t*dt - ts1 <= t_refr] = 0\n",
    "\n",
    "\t\t\t## Process hidden neuron spikes\n",
    "\t\t\tfired = np.nonzero(V1 >= Vth) # Hidden neurons that spiked\n",
    "\t\t\tV1[fired] = 0 # Reset their membrane potential to zero\n",
    "\t\t\tts1[fired] = t # Update their most recent spike times\n",
    "\n",
    "\t\t\t# Make array of hidden-neuron spikes\n",
    "\t\t\tST1 = np.zeros(n_h1)\n",
    "\t\t\tST1[fired] = 1\n",
    "\n",
    "\t\t\t# Update output neuron synaptic currents\n",
    "\t\t\tI2 += (dt/t_syn1)*(w_out.dot(ST1) - I2)\n",
    "\n",
    "\t\t\t# Update output neuron membrane potentials\n",
    "\t\t\tV2 += (dt/t_mH)*((V_rest - V2) + I2*(RH))\n",
    "\t\t\tV2[V2 < -VthO/10] = -VthO/10 # Limit negative potential to -Vth0/10\n",
    "\n",
    "\t\t\t# Clear V of output neurons that spiked more recently than t_refr\n",
    "\t\t\trefr2 = (t*dt - ts2 <= t_refr)\n",
    "\t\t\tV2[refr2] = 0\n",
    "\n",
    "\t\t\t## Process output spikes\n",
    "\t\t\tfired2 = np.nonzero(V2 >= VthO) # output neurons that spikes\n",
    "\t\t\tV2[fired2] = 0 # Reset their membrane potential to zero\n",
    "\t\t\tts2[fired2] = t # Update their most recent spike times\n",
    "\n",
    "\t\t\t# Make array of output neuron spikes\n",
    "\t\t\tST2 = np.zeros(n_out)\n",
    "\t\t\tST2[fired2] = 1\n",
    "\n",
    "\t\t\tcnt += ST2\n",
    "\n",
    "\t\tif np.count_nonzero(cnt) != 0:  # Avoid counting no spikes as predicting label 0\n",
    "\t\t\tprediction = np.argmax(cnt)\n",
    "\t\t\ttarget = labels[u]\n",
    "\t\t\tif prediction == target:\n",
    "\t\t\t\tnumCorrect += 1\n",
    "\n",
    "\treturn numCorrect/len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f86c9f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_load():\n",
    "    TrainIm_ = np.load(\"Resnet18_FE_Train_Data_Scaled.npy\")\n",
    "    TestIm_ = np.load(\"Resnet18_FE_Test_Data_Scaled.npy\")\n",
    "    TrainL_ = np.load(\"Resnet18_FE_Train_Labels.npy\")\n",
    "    TestL_ = np.load(\"Resnet18_FE_Test_Labels.npy\")\n",
    "    \n",
    "    return TrainIm_, TrainL_, TestIm_, TestL_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9eb9d97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainIm_, TrainL_, TestIm_, TestL_ = data_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dc7c987",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_factor = 7\n",
    "w_in_max = 3\n",
    "w_out_max = 1.5\n",
    "\n",
    "current_path = os.path.abspath(os.path.dirname(__file__))\n",
    "file_path = os.path.join(current_path, \"HfOx_device_data_placeholder.csv\")\n",
    "\n",
    "memristor_data = pd.read_csv(file_path)\n",
    "\n",
    "mean_res = np.array(memristor_data[\"Resistance_level_mean\"])\n",
    "std_res = np.array(memristor_data[\"Resistance_level_std\"])\n",
    "\n",
    "# The device data has been collected from Liehr, Maximilian, et al. \"Impact of switching variability of 65nm CMOS integrated hafnium dioxide-based ReRAM devices on distinct level operations.\" 2020 IEEE International Integrated Reliability Workshop (IIRW). IEEE, 2020.\n",
    "\n",
    "n_res_level = len(mean_res)\n",
    "n_cross = 7\n",
    "R_fh, R_bh, R_fo, R_bo = res_param_config(mean_res, std_res, n_cross, w_in_max, w_out_max)\n",
    "\n",
    "# task parameters\n",
    "n_train = 50000\n",
    "n_test = 10000\n",
    "maxE = 1\n",
    "\n",
    "n_runs = 5\n",
    "n_tasks = 5\n",
    "taskID = np.array([[0, 1], [2, 3], [4, 5], [6,7], [8, 9]])\n",
    "\n",
    "#Learning rule parameters\n",
    "Imin = -4\n",
    "Imax = 4\n",
    "lr0 = 0.1*lr_factor\n",
    "lr1 = 1e-3*lr_factor\n",
    "w_scale0 = 1e-0 # Weight scale in hidden layer\n",
    "w_scale1 = 1e-0 # Weight scale at output layer\n",
    "FPF = 1 # inhibits punshing target neuron (only use if training a specific output spike pattern)\n",
    "     \n",
    "\n",
    "\n",
    "# Simulation parameters\n",
    "tSim = 0.15 # Duration of simulation (seconds)\n",
    "MaxF = 250\n",
    "maxFL = 100\n",
    "dt = 1 # time resolution\n",
    "dt_conv = 1e-3 # Data is sampled in ms\n",
    "nBins = int(tSim/dt_conv) #total no. of time steps\n",
    "\n",
    "# Network architecture parameters\n",
    "n_h1 = 200  # no. of hidden neurons\n",
    "n_in = 512  # no. of input neurons\n",
    "n_out = 2   # no. of output neurons \n",
    "nTrials = n_in\n",
    "\n",
    "\n",
    "# Neuron parameters\n",
    "t_syn = 10\n",
    "t_syn1 = 25\n",
    "t_m = 15\n",
    "t_mH = 25\n",
    "t_mU = 15\n",
    "t_mE = 10\n",
    "t_tr = 25\n",
    "R = 1\n",
    "RH = 5\n",
    "RU = 5\n",
    "RE = 25\n",
    "Vs = 15\n",
    "VsO = 10\n",
    "VsE = 1\n",
    "V_rest = 0 # Resting membrane potential\n",
    "t_refr = 4 # Duration of refractory period\n",
    "\n",
    "Vth = (1/t_m)*R*Vs # Hidden neuron threshold\n",
    "VthO = (1/t_mH)*RH*VsO # Output neuron threshold\n",
    "VthE = (1/t_mE)*RE*VsE # Error neuron threshold\n",
    "\n",
    "\n",
    "seeds = []\n",
    "\n",
    "\n",
    "U_in = 0.3 \n",
    "U_out = 2.5 \n",
    "\n",
    "\n",
    "\n",
    "m_in_max = 10\n",
    "m_out_max = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9c92dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mem_cont_train (m_th_in,dm_in,m_th_hid,dm_out,m_th_out):\n",
    "\n",
    "    np.random.seed(2)\n",
    "    Acc = np.zeros((n_tasks,n_tasks,n_runs))\n",
    "\n",
    "    for run in range(n_runs):\n",
    "        m_in = np.zeros((n_h1, n_in))   # every run the metaplasticity factors start at 0\n",
    "        m_out = np.zeros((n_out, n_h1))\n",
    "\n",
    "        # Randomly select train and test samples\n",
    "        trainInd = np.random.choice(len(TrainIm_), n_train, replace=False)\n",
    "        TrainIm = TrainIm_[trainInd]\n",
    "        TrainLabels = TrainL_[trainInd]\n",
    "\n",
    "        testInd = np.random.choice(len(TestIm_), n_test, replace=False)\n",
    "        TestIm = TestIm_[testInd]\n",
    "        TestLabels = TestL_[testInd]\n",
    "\n",
    "        # Generate forward pass weights\n",
    "        w_in, r_in = weight_initialize_var(n_h1, n_in, R_fh, R_bh, n_cross, w_in_max)\n",
    "        w_out, r_out = weight_initialize_var(n_out, n_h1, R_fo, R_bo, n_cross, w_out_max)\n",
    "\n",
    "\n",
    "        # Generate random feedback weights\n",
    "        w_err_factor = 0.15\n",
    "        w_err_h1p = ((np.random.rand(n_h1,n_out))*2-1)*w_err_factor # these are random numbers from -1 to 1\n",
    "        w_err_h1n = w_err_h1p\n",
    "\n",
    "        cross_ind_in = 0 \n",
    "        cross_ind_out = 0\n",
    "\n",
    "        for d in range(n_tasks): #n_tasks\n",
    "\n",
    "            trainInd = np.concatenate((np.where(TrainLabels == taskID[d,0])[0],np.where(TrainLabels == taskID[d,1])[0]),axis=0)\n",
    "            n_train2 = len(trainInd)\n",
    "            trainInd2 = np.random.choice(len(trainInd), n_train2, replace=False)\n",
    "            trainInd = trainInd[trainInd2]\n",
    "            taskLabels = TrainLabels[trainInd]\n",
    "            trainSet = TrainIm[trainInd]\n",
    "            taskID2 = np.where(taskLabels == taskID[d,1])[0]\n",
    "            taskLabelsF = np.zeros(len(trainInd));\n",
    "            taskLabelsF[taskID2] = 1\n",
    "\n",
    "            n_train2 = len(trainInd)\n",
    "           \n",
    "\n",
    "            for e in range(maxE):\n",
    "                for u in range(n_train2): \n",
    "                    c_in = np.zeros([n_h1,n_in])   # for every sample the no of updates to w starts with 0\n",
    "                    c_out = np.zeros([n_out, n_h1])\n",
    "                    \n",
    "                    im = trainSet[u]\n",
    "                    fr = im*MaxF\n",
    "                    spikeMat = MNIST_to_Spikes(MaxF, trainSet[u], tSim, dt_conv)\n",
    "                    fr_label = np.zeros(n_out)\n",
    "                    fr_label[int(taskLabelsF[u])] = maxFL # target output spiking frequencies\n",
    "                    s_label = make_spike_trains(fr_label*dt_conv, nBins) # target spikes\n",
    "                    Xh_in = np.zeros(n_in)\n",
    "\n",
    "                    # Initialize hidden layer variables\n",
    "                    I1 = np.zeros(n_h1)\n",
    "                    V1 = np.zeros(n_h1)\n",
    "                    U1 = np.zeros(n_h1)\n",
    "                    Xh_hid = np.zeros(n_h1)\n",
    "\n",
    "                    # Initialize output layer variables\n",
    "                    I2 = np.zeros(n_out)\n",
    "                    V2 = np.zeros(n_out)\n",
    "                    U2 = np.zeros(n_out)\n",
    "                    Xh_out = np.zeros(n_out)\n",
    "\n",
    "                    # Initialize error neuron variables\n",
    "                    Verr1 = np.zeros(n_out)\n",
    "                    Verr2 = np.zeros(n_out)\n",
    "\n",
    "                    # Initialize firing time variables\n",
    "                    ts1 = np.full(n_h1, -t_refr)\n",
    "                    ts2 = np.full(n_out, -t_refr)\n",
    "\n",
    "                    for t in range(nBins):\n",
    "                        # Forward pass\n",
    "\n",
    "                        # Find input neurons that spike\n",
    "                        ST0 = spikeMat[:, t]\n",
    "                        fired_in = np.nonzero(ST0)\n",
    "                        Xh_in = Xh_in + ST0 - Xh_in/t_tr\n",
    "\n",
    "                        # Update synaptic current into hidden layer\n",
    "                        I1 += (dt/t_syn) * (w_in.dot(spikeMat[:, t]) - I1)\n",
    "\n",
    "                        # Update hidden layer membrane potentials\n",
    "                        V1 += (dt/t_m) * ((V_rest - V1) + I1 * R)\n",
    "                        V1[V1 < -Vth/10] = -Vth/10 # Limit negative potential\n",
    "\n",
    "                        # If neuron in refractory period, prevent changes to membrane potential\n",
    "                        refr1 = (t*dt - ts1 <= t_refr)\n",
    "                        V1[refr1] = 0\n",
    "\n",
    "                        fired = np.nonzero(V1 >= Vth) # Hidden neurons that spiked\n",
    "                        V1[fired] = 0 # Reset their membrane potential to zero\n",
    "                        ts1[fired] = t # Update their most recent spike times\n",
    "\n",
    "                        ST1 = np.zeros(n_h1) # Hidden layer spiking activity\n",
    "                        ST1[fired] = 1 # Set neurons that spiked to 1\n",
    "                        Xh_hid = Xh_hid + ST1 - Xh_hid/t_tr\n",
    "                        \n",
    "\n",
    "                        # Repeat the process for the output layer\n",
    "                        I2 += (dt/t_syn1)*(w_out.dot(ST1) - I2)\n",
    "\n",
    "                        V2 += (dt/t_mH)*((V_rest - V2) + I2*(RH))\n",
    "                        V2[V2 < -VthO/10] = -VthO/10\n",
    "\n",
    "                        refr2 = (t*dt - ts2 <= t_refr)\n",
    "                        V2[refr2] = 0\n",
    "                        fired2 = np.nonzero(V2 >= VthO)\n",
    "\n",
    "                        V2[fired2] = 0\n",
    "                        ts2[fired2] = t\n",
    "\n",
    "                        # Make array of output neuron spikes\n",
    "                        ST2 = np.zeros(n_out)\n",
    "                        ST2[fired2] = 1\n",
    "                        Xh_out = Xh_out + ST2 - Xh_out/t_tr\n",
    "                       \n",
    "\n",
    "                        # Compare with target spikes for this time step\n",
    "                        Ierr = (ST2 - s_label[:, t])\n",
    "\n",
    "                        # Update false-positive error neuron membrane potentials\n",
    "                        Verr1 += (dt/t_mE)*(Ierr*RE)\n",
    "                        Verr1[Verr1 < -VthE/10] = -VthE/10 # Limit negative potential to -VthE/10\n",
    "\n",
    "                        ## Process spikes in false-positive error neurons\n",
    "                        fired_err1 = np.nonzero(Verr1 >= VthE)\n",
    "                        Verr1[fired_err1] -= VthE\n",
    "\n",
    "                        # Don't penalize \"false positive\" spikes on the target\n",
    "                        Verr1[int(taskLabelsF[u])] *= FPF\n",
    "                        label_rec[u] = int(taskLabelsF[u])\n",
    "\n",
    "                        # Make array of false-positive error neuron spikes\n",
    "                        Serr1 = np.zeros(n_out)\n",
    "                        Serr1[fired_err1] = 1\n",
    "\n",
    "                        # Update false-negative error neuron membrane potentials\n",
    "                        Verr2 -= (dt/t_mE)*(Ierr*RE)\n",
    "                        Verr2[Verr2 < -VthE/10] = -VthE/10\n",
    "\n",
    "                        ## Process spikes in false-negative error neurons\n",
    "                        fired_err2 = np.nonzero(Verr2 >= VthE)\n",
    "                        Verr2[fired_err2] -= VthE\n",
    "\n",
    "\n",
    "                        # Make array of false-negative error neuron spikes\n",
    "                        Serr2 = np.zeros(n_out)\n",
    "                        Serr2[fired_err2] = 1\n",
    "\n",
    "\n",
    "                        # Update hidden neuron error compartments (using random weights)\n",
    "                        U1 += (dt/t_mU)*( (w_err_h1p.dot(Serr1) - w_err_h1n.dot(Serr2))*RU)\n",
    "\n",
    "                        # Update output neuron error compartments\n",
    "                        U2 += (dt/t_mU)*( (Serr1 - Serr2)*RU)\n",
    "\n",
    "                        up_hid = np.where(np.abs(U1)>U_in)[0]\n",
    "                        up_out = np.where(np.abs(U2)>U_out)[0]\n",
    "\n",
    "\n",
    "                        if len(up_hid)>0: # if any neuron error has passed threshold\n",
    "                            post_ind = np.nonzero((I1[up_hid]>Imin) & (I1[up_hid]<Imax))[0]\n",
    "                            if len(post_ind)>0:\n",
    "                                if len(fired_in[0]) != 0:\n",
    "                                    s = np.sign(U1[up_hid[post_ind]])  # getting the sign of the errors, it is 1 if U2 positive, -1 if if U2 negative, 0 if U2 is zero\n",
    "                                    U1[up_hid[post_ind]] = 0\n",
    "                                    pre_ind = fired_in  # collects the location of the pre-synaptic neurons\n",
    "                                    m_up = m_in[np.ix_(up_hid[post_ind], pre_ind[0])] # takes the m value of the post-synaptic neuron\n",
    "                                    UF = np.matlib.repmat(np.reshape(s, (len(s),1)),1, len(pre_ind[0])) # extends the error\n",
    "                                    r_up = r_in[np.ix_(up_hid[post_ind], pre_ind[0], np.linspace(0,n_cross-1, n_cross ).astype(int))]\n",
    "                                    w_up = res_to_weight(r_up, R_fh, R_bh) #compute the candidate weights for update\n",
    "                                    w_th = (np.exp(-m_up*np.abs(w_up)))\n",
    "                                    w_rand = np.random.rand()\n",
    "                                    UF[np.where(w_rand>w_th)] =0\n",
    "                                    c_in = np.zeros([n_h1,n_in])\n",
    "                                    c_in[np.ix_(up_hid[post_ind], pre_ind[0])] -= UF \n",
    "                                    up_in_mem = np.where(c_in!=0)\n",
    "                                    if len(up_in_mem[0])>0:\t\t\t\t\t\t\t\t\t\t\t\n",
    "                                        cross_ind_in = cross_ind_in+1 \n",
    "                                        current_ind = int(cross_ind_in%n_cross)\n",
    "                                        c_up = c_in[up_in_mem]\n",
    "                                        r_in_up = r_in[up_in_mem][:,current_ind]\n",
    "                                        r_in[up_in_mem[0], up_in_mem[1],current_ind] = res_program(r_in_up, c_up)\n",
    "                                        w_in[up_in_mem]  = res_to_weight(r_in[up_in_mem], R_fh, R_bh)\n",
    "                                        c_in = np.zeros([n_h1,n_in])\n",
    "\n",
    "\n",
    "\n",
    "                        if len(up_out)>0: # if any neuron error has passed threshold\n",
    "                            post_ind = np.nonzero((I2[up_out]>Imin) & (I2[up_out]<Imax))[0]\n",
    "                            if len(post_ind)>0:\t\n",
    "                                if len(fired[0]) != 0:\n",
    "                                    s = np.sign(U2[up_out[post_ind]]) \n",
    "                                    U2[up_out[post_ind]] = 0\n",
    "                                    pre_ind = fired  # collects the location of the pre-synaptic neurons\n",
    "                                    m_up = m_out[np.ix_(up_out[post_ind], pre_ind[0])] # takes the m value of the post-synaptic neuron\n",
    "                                    UF = np.matlib.repmat(np.reshape(s, (len(s),1)),1, len(pre_ind[0])) # extends the error\n",
    "                                    r_up = r_out[np.ix_(up_out[post_ind], pre_ind[0], np.linspace(0,n_cross-1, n_cross ).astype(int))]\n",
    "                                    w_up = res_to_weight(r_up, R_fo, R_bo) #compute the candidate weights for update\n",
    "                                    w_th = (np.exp(-m_up*np.abs(w_up)))\n",
    "                                    w_rand = np.random.rand()\n",
    "                                    UF[np.where(w_rand>w_th)] =0 \n",
    "                                    c_out = np.zeros([n_out, n_h1]) \n",
    "                                    c_out[np.ix_(up_out[post_ind], pre_ind[0])] -= UF \n",
    "                                    up_out_mem = np.where(c_out!=0)\t\t\t\t\n",
    "                                    if len(up_out_mem[0])>0:\n",
    "                                        cross_ind_out = cross_ind_out+1 \n",
    "                                        current_ind = int(cross_ind_out%n_cross)\n",
    "                                        c_up = c_out[up_out_mem]\n",
    "                                        r_out_up = r_out[up_out_mem][:,current_ind]\n",
    "                                        r_out[up_out_mem[0], up_out_mem[1],current_ind] = res_program(r_out_up, c_up)\n",
    "                                        w_out[up_out_mem] = res_to_weight(r_out[up_out_mem], R_fo, R_bo)\n",
    "                                        c_out = np.zeros([n_out, n_h1]) \n",
    "\n",
    "                    h_in = np.where(Xh_in>m_th_in)[0]\n",
    "                    h_hid = np.where(Xh_hid>m_th_hid)[0]\n",
    "                    h_out = np.where(Xh_out>m_th_out)[0]\n",
    "                    m_in[np.ix_(h_hid,h_in)] = m_in[np.ix_(h_hid,h_in)] + dm_in\n",
    "                    m_out[np.ix_(h_out,h_hid)] = m_out[np.ix_(h_out,h_hid)] + dm_out\n",
    "                    m_in[np.where(m_in > m_in_max)] = m_in_max\n",
    "                    m_out[np.where(m_out > m_out_max)] = m_out_max\n",
    "\n",
    "\n",
    "\n",
    "            for d2 in range(d+1):\n",
    "\n",
    "                testInd = np.concatenate((np.where(TestLabels == taskID[d2,0])[0],np.where(TestLabels == taskID[d2,1])[0]),axis=0)\n",
    "                taskLabels = TestLabels[testInd]\n",
    "                testSet = TestIm[testInd]\n",
    "                taskID2 = np.where(taskLabels == taskID[d2,1])[0]\n",
    "                taskLabelsT = np.zeros(len(testInd))\n",
    "                taskLabelsT[taskID2] = 1\n",
    "\n",
    "                Acc[d2, d, run] = check_accuracy(testSet, taskLabelsT, w_in, w_out )\n",
    "\n",
    "\n",
    "\n",
    "    avg_task_acc = np.mean(Acc,axis=2)\n",
    "    avg_task_std = np.std(Acc,axis=2)\n",
    "    class_cont_Acc= np.zeros(n_tasks)\n",
    "    class_cont_std =np.zeros(n_tasks)\n",
    "    for i in range(n_tasks):\n",
    "        class_cont_Acc[i] = avg_task_acc[i,n_tasks-1]\n",
    "        class_cont_std[i] = avg_task_std[i,n_tasks-1]\n",
    "\n",
    "    class_Acc= np.zeros(n_tasks)\n",
    "    class_std =np.zeros(n_tasks)\n",
    "    for i in range(n_tasks):\n",
    "        class_Acc[i] = avg_task_acc[i,i]\n",
    "        class_std[i] = avg_task_std[i,i]\n",
    "    cont_acc = np.mean(Acc,axis=0)[n_tasks-1]\n",
    "\n",
    "\n",
    "    mean_cont_acc = np.mean(cont_acc)\n",
    "    std_cont_acc = np.std(cont_acc)\n",
    "    results = {'dm_in': dm_in, 'dm_out': dm_out, 'm_th_in': m_th_in, 'm_th_hid':m_th_hid, 'm_th_out': m_th_out, 'class_Acc':class_Acc, 'class_std':class_std, 'class_cont_Acc':class_cont_Acc, 'class_cont_std':class_cont_std, 'cont_mean' : mean_cont_acc, 'cont_std' : std_cont_acc,  'Acc' : Acc}\n",
    "\n",
    "    jsonString = json.dumps(results, indent=4, cls=NumpyEncoder)\n",
    "\n",
    "    s1 = str(m_th_in)\n",
    "    s1.replace(\".\",\"_\")\n",
    "    s2 = str(m_th_hid)\n",
    "    s2.replace(\".\",\"_\")\n",
    "    s3 = str(m_th_out)\n",
    "    s3.replace(\".\",\"_\")\n",
    "    s4 = str(dm_in*10000)\n",
    "    s5 = str(dm_out*10000)\n",
    "    name= \"cifar_cnt_\"+s1+s2+s3+s4+s5\n",
    "    filename = \"%s.json\" % name\n",
    "    jsonFile = open(filename, \"w\")\n",
    "    jsonFile.write(jsonString)\n",
    "    jsonFile.close()\n",
    "    \n",
    "    \n",
    "    return np.mean(Acc[:,-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea264e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 0\n",
      "Task 1\n",
      "Task 2\n",
      "Task 3\n",
      "Task 4\n",
      "Task 0\n",
      "Task 1\n",
      "Task 2\n",
      "Task 3\n",
      "Task 4\n",
      "Task 0\n",
      "Task 1\n",
      "Task 2\n",
      "Task 3\n",
      "Task 4\n",
      "Task 0\n",
      "Task 1\n",
      "Task 2\n",
      "Task 3\n",
      "Task 4\n",
      "Task 0\n",
      "Task 1\n",
      "Task 2\n",
      "Task 3\n",
      "Task 4\n"
     ]
    }
   ],
   "source": [
    "cont_Acc = mem_cont_train (3,60e-4,2.75,25e-4,1.6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
